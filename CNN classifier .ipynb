{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d32da0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b00b3047",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/Aayush Garg/Downloads/output whole data indexed (1).csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29c37566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "data = pd.read_csv(\"C:/Users/Aayush Garg/Downloads/output whole data indexed (1).csv\")  \n",
    "\n",
    "\n",
    "data = data.dropna(subset=['clause_text', 'clause_type'])\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "data['label'] = label_encoder.fit_transform(data['clause_type'])\n",
    "\n",
    "# Step 5: Split the Data into Training and Testing Sets\n",
    "X = data['clause_text']\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Tokenization and Padding\n",
    "max_sequence_length = 1000  \n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(X_train, maxlen=max_sequence_length)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(X_test, maxlen=max_sequence_length)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73d5c9d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,  # tokenized and padded text data\n",
    "    y,  #  encoded labels\n",
    "    test_size=0.2,  \n",
    "    random_state=42 \n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af161fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum index value in the tokenizer's word index: 23020\n"
     ]
    }
   ],
   "source": [
    "max_index = max(tokenizer.word_index.values())\n",
    "print(f\"Maximum index value in the tokenizer's word index: {max_index}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff03f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    input_dim=vocab_size,  \n",
    "    output_dim=100,  \n",
    "    input_length=max_sequence_length\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7ca67468",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  # Add 1 for the padding token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ae628404",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23021"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0c085f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e3a26af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "747/747 [==============================] - 147s 196ms/step - loss: 1.9956 - accuracy: 0.4765 - val_loss: 1.0166 - val_accuracy: 0.7422\n",
      "Epoch 2/5\n",
      "747/747 [==============================] - 148s 199ms/step - loss: 0.6825 - accuracy: 0.8191 - val_loss: 0.7596 - val_accuracy: 0.8164\n",
      "Epoch 3/5\n",
      "747/747 [==============================] - 146s 195ms/step - loss: 0.3545 - accuracy: 0.8979 - val_loss: 0.7796 - val_accuracy: 0.8052\n",
      "Epoch 4/5\n",
      "747/747 [==============================] - 142s 190ms/step - loss: 0.2288 - accuracy: 0.9324 - val_loss: 0.9131 - val_accuracy: 0.8042\n",
      "Epoch 5/5\n",
      "747/747 [==============================] - 146s 195ms/step - loss: 0.1711 - accuracy: 0.9469 - val_loss: 0.9344 - val_accuracy: 0.8127\n",
      "187/187 [==============================] - 6s 30ms/step - loss: 0.9344 - accuracy: 0.8127\n",
      "Test Loss: 0.9344, Test Accuracy: 0.8127\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"filtered_data.csv1\")  \n",
    "\n",
    "\n",
    "# Tokenization and Padding\n",
    "max_sequence_length = 1000\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data['clause_text'])\n",
    "X = tokenizer.texts_to_sequences(data['clause_text'])\n",
    "X = pad_sequences(X, maxlen=max_sequence_length)\n",
    "\n",
    "# Label Encoding\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(data['clause_type'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=100, input_length=max_sequence_length)) \n",
    "model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(len(label_encoder.classes_), activation='softmax'))  \n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=5, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ef79232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aayush Garg\\anaconda3\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.save('your_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "efdfa82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(\"your_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ea08bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter The Text ---During the Access Term, Gene Logic, at its expense, will provide Genaissance: (a) any subsequent release or version of the Gene Logic Software (including bug fixes, patches and maintenance releases) included in the GeneExpress(TM) Product as Gene Logic makes such releases available to its other customers; and (b) support and maintenance of Gene Logic Software included in the GeneExpress(TM) Product through reasonable consultation via telephone, fax, electronic mail or otherwise during Gene Logic's normal business hours (8:00 a.m. to 5:00 p.m. Eastern Time on regular U.S. business days, holidays excepted) on specific problems that arise in the delivery and use of the GeneExpress(TM) Product. Should Genaissance request on-site support or maintenance it will pay Gene Logic's reasonable out-of-pocket expenses and a daily consultation fee of ************************ during the Access Term.\n"
     ]
    }
   ],
   "source": [
    "new_text = input(\"Enter The Text ---\") \n",
    "new_text_sequences = tokenizer.texts_to_sequences(new_text)\n",
    "new_text_padded = pad_sequences(new_text_sequences, maxlen=max_sequence_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8aab1ca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 38ms/step\n",
      "Predicted Clause Type: Definitions\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(new_text_padded)\n",
    "\n",
    "predicted_class_index = np.argmax(predictions[0])\n",
    "\n",
    "\n",
    "predicted_clause_type = label_encoder.classes_[predicted_class_index]\n",
    "\n",
    "print(f'Predicted Clause Type: {predicted_clause_type}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
